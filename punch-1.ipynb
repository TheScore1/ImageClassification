{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "import numpy as np\n",
    "\n",
    "class OnePunchManDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.annotations['class'].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[idx, 1])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.class_to_idx[self.annotations.iloc[idx, 2]]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    \n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    \n",
    "    y_a, y_b = y, y[index]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "csv_file = 'one-punch-man/train.csv'\n",
    "root_dir = 'one-punch-man'\n",
    "dataset = OnePunchManDataset(csv_file=csv_file, root_dir=root_dir, transform=train_transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        self.efficientnet = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "        num_features = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier = nn.Identity()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "num_classes = len(dataset.class_to_idx)\n",
    "model = ImprovedCNN(num_classes=num_classes).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = CyclicLR(optimizer, base_lr=0.00001, max_lr=0.0001, step_size_up=10, mode='triangular')\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, scheduler, alpha=1.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        if np.random.rand() > 0.5:\n",
    "            images, labels_a, labels_b, lam = mixup_data(images, labels, alpha)\n",
    "            loss_fn = mixup_criterion\n",
    "        else:\n",
    "            images, labels_a, labels_b, lam = cutmix_data(images, labels, alpha)\n",
    "            loss_fn = mixup_criterion\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(criterion, outputs, labels_a, labels_b, lam)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return val_loss / len(val_loader), val_accuracy\n",
    "\n",
    "num_epochs = 60\n",
    "best_val_accuracy = 0.0\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, scheduler, alpha=1.0)\n",
    "    val_loss, val_accuracy = validate(model, val_loader, criterion)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "    \n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "def predict(model, img_path, transform):\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).cuda()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "test_folder = 'one-punch-man/test/test'\n",
    "predictions = []\n",
    "\n",
    "for img_name in os.listdir(test_folder):\n",
    "    if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(test_folder, img_name)\n",
    "        prediction = predict(model, img_path, val_transform)\n",
    "        predicted_class = list(dataset.class_to_idx.keys())[prediction]\n",
    "        predictions.append({'id': img_name.split('.')[0], 'path': img_name, 'class': predicted_class})\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
